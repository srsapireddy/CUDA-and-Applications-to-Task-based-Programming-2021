{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZSu8VYvuqZI",
        "outputId": "6e4af9d6-f0fc-4ce0-96c0-db5f27adec6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa36t5V4usvf",
        "outputId": "929a29e8-e96d-4b2d-8f5b-841c5ed48331"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-hyngt3gh\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-hyngt3gh\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=d2388a587218b0723527697549a148a28f3e785e83e0d7ab8e6df3eec8a68bd4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ylfr6ya/wheels/db/c1/1f/a2bb07bbb4a1ce3c43921252aeafaa6205f08637e292496f04\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfqblYqiu0I8",
        "outputId": "f5e6c49e-a8d0-42d6-baf3-dc6ff0376d2c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name testGoogleColab.cu\n",
        "\n",
        "#include <cuda_runtime_api.h>\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <chrono>\n",
        "#include <tuple>\n",
        "#include <utility>\n",
        "#include <numeric>\n",
        "#include <iomanip>\n",
        "#include \"utility/utility.h\"\n",
        "\n",
        "// Declare a GPU-visible floating point variable in global memory.\n",
        "__device__ float dResult;\n",
        "\n",
        "/*\n",
        " The most basic reduction kernel uses atomic operations to accumulate\n",
        " the individual inputs in a single, device-wide visible variable.\n",
        " If you have experience with atomics, it is important to note that the\n",
        " basic atomicXXX instructions of CUDA have RELAXED semantics (scary!).\n",
        " That means, the threads that operate atomically on them only agree that \n",
        " there is a particular order for the accesses to that variable and nothing\n",
        " else (especially no acquire/release semantics).\n",
        "*/\n",
        "__global__ void reduceAtomicGlobal(const float* __restrict input, int N)\n",
        "{\n",
        "    const int id = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "    /* \n",
        "    Since all blocks must have the same number of threads,\n",
        "    we may have to launch more threads than there are \n",
        "    inputs. Superfluous threads should not try to read \n",
        "    from the input (out of bounds access!)\n",
        "    */\n",
        "    if (id < N)\n",
        "        atomicAdd(&dResult, input[id]);\n",
        "}\n",
        "\n",
        "/*\n",
        " First improvement: shared memory is much faster than global\n",
        " memory. Each block can accumulate partial results in isolated\n",
        " block-wide visible memory. This relieves the contention on \n",
        " a single global variable that all threads want access to.\n",
        "*/\n",
        "__global__ void reduceAtomicShared(const float* __restrict input, int N)\n",
        "{\n",
        "    const int id = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // Declare a shared float for each block\n",
        "    __shared__ float x;\n",
        "\n",
        "    // Only one thread should initialize this shared value\n",
        "    if (threadIdx.x == 0) \n",
        "        x = 0.0f;\n",
        "    \n",
        "    /*\n",
        "    Before we continue, we must ensure that all threads\n",
        "    can see this update (initialization) by thread 0\n",
        "    */\n",
        "    __syncthreads();\n",
        "\n",
        "    /*\n",
        "    Every thread in the block adds its input to the\n",
        "    shared variable of the block.\n",
        "    */\n",
        "    if (id < N) \n",
        "        atomicAdd(&x, input[id]);\n",
        "\n",
        "    // Wait until all threads have done their part\n",
        "    __syncthreads();\n",
        "\n",
        "    /*\n",
        "    Once they are all done, only one thread must add\n",
        "    the block's partial result to the global variable. \n",
        "    */\n",
        "    if (threadIdx.x == 0) \n",
        "        atomicAdd(&dResult, x);\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wtcFvnjHu2fE",
        "outputId": "675a3dcd-2810-44cb-cbc3-d1ab57f3053f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/testGoogleColab.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}